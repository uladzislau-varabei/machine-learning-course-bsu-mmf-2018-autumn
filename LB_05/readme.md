# Лабораторная работа №5
## Сверточные нейронные сети (CNN)

В данной работе будет работать с датасетом `CIFAR-10`. Ваша задача научиться предсказывать класс изображений. Целевая метрика — **accuracy**.

Данную работу предлагается выполнять на `Tensorflow` (для установки в `Anaconda Prompt` выполнить `conda install tensorflow`).

1. Скачайте версию данных для Python: https://www.cs.toronto.edu/~kriz/cifar.html
2. Загрузите данные и сохраните изображения в png-файлы, предварительно изменив размеры массива на (32, 32, 3) для каждого конкретного примера. Также создайте отдельный словарь вида `{filename:label}` и сохраните его в виде json-файла (или создайте DataFrame и сохраните его в csv-файл).
3. Загрузите и отобразите несколько из созданных вами файлов. Сколько изображений доступно для каждого класса в тренировочном множестве?
4. Разделите файлы для обучения на два множества: тренировочное (80%) и валидационное (20%). Для этого используйте `sklearn.model_selection.train_test_split` с фиксированным параметром `random_state`.
5. Закодируйте классы изображения one-hot векторами (например, при помощи `keras.utils.to_categorical` или `sklearn.preprocessing.OneHotEncoder`).
6. Напишите генератор, который на входе принимает список файлов и размер батча, а на выходе выдает батч из загруженных изображений заданного размера и one-hot вектора, соответствующие их классам.
7. Напишите функцию, которая будет случайным образом аугментировать батч изображений. Покажите примеры ее работы. В генератор из предыдущего пункта добавьте параметр, отвечающий за необходимость аугментирования изображений.
8. Создайте модель нейронной сети, которая состоит из двух сверточных блоков, за которыми идут несколько полносвязных слоев с батч-нормализацией и дропаутом.
    * Сверточный блок должен иметь вид: `Convolution2D -> Convolution2D -> MaxPooling2D`
    * Для сверточных слоев используйте 32/64/128 фильтров
    * Выход последнего сверточного слоя необходимо распрямить в вектор
    * Для полносвязных слоев используйте 64-512 нейронов
    * Рекомендуется использовать 1-3 полносвязных слоя
    * Последним должен быть softmax-слой, у которого количество нейронов равно количеству классов
9. Задайте функцию потерь и оптимизатор модели. Сохраните операции в переменные `loss` и `train_op` — их будет необходимо выполнять на каждом шаге обучения сети.
10. Обучите модель. 
11. Постройте совместные графики метрики и функции потерь для тренировочных и валидационных данных.
12. Предскажите результаты для тестового множества и вычислите значений целевой метрики. Какое качество показывает модель на разных классах?
13. Поэкспериментируйте с архитектурой сети и процессом ее обучения:
    * Замените `MaxPooling2D` в сверточных блоках на `AveragePooling2D`. Как изменился результат/время обучения?
    * Обучите сеть без аугментации изображений. Как сильно она влияет на результат? 
    * Измените количество нейронов в сверточных слоях. Лучше их постепенно увеличивать/уменьшать?
    * Поэкспериментируйте с параметрами сверточных слоев
    * Попробуйте другие функции активации в сверточных/полносвязных слоях
    * Уменьшите/увеличите количество полносвязных слоев, как это влияет на качество?
    * Увеличивается ли точность сети при добавлении батч-нормализации/дропаута в сверточные блоки? Насколько это замедляет процесс обучения?
14. Опишите модель, которая показала лучший результат.
15. Отправьте отчет преподавателю.

**Условие работы будет дополнено.**
   
**Сро сдачи работы: 26 октября 2018.