# Лабораторная работа №4
## Введение в нейронные сети

В данной лабораторной работе будет работать с датасетом Fashion MNIST. Вам будет необходимо научиться предсказывать класс одежды на основе черно-белого изображения размером 28x28 пикселей. В качестве метрики будем использовать **accuracy**.

Установите библиотеку `Keras` (в Anaconda Prompt выполните команду `conda install keras`). Рекомендуется также установить progress bar для keras https://github.com/bstriner/keras-tqdm (там же есть примеры, как его использовать при обучении моделей).

1. Загрузите данные.
2. Проведите разведочный анализ: постройте изображения различных классов, посмотрите распределение классов.
3. Картинки необходимо предобработать: приведите их к типу float, отобразите значение их пикселей в отрезок [0,1], распрямите матрицу в вектор размера (1, 28x28).
4. Закодируйте классы изображения one-hot векторами (например, при помощи `keras.utils.to_categorical` или `sklearn.preprocessing.OneHotEncoder`).
5. Разделите тренировочные данные на два множества: тренировочное (80%) и валидационное (20%). Для этого используйте `sklearn.model_selection.train_test_split` с фиксированным параметром `random_state`.
6. Напишите генератор, который на входе принимает переменные x, y, batch_size, и возвращает батчи размера batch_size.
7. Создайте модель нейронной сети, которая будет состоять из 3 полносвязных слоев, после которых идет softmax-слой с количеством нейронов равным количесству классов. 
    * Слои должны иметь вид: `Dense -> Activation -> BatchNormalization -> Dropout`.
    * Перед первым полносвязным слоем для удобства можно использовать слой `Input`.
    * В качестве функции активации используйте `relu`.
    * Для количества нейронов в слоях используйте числа 64, 128, 256, 512. Учтите, что с ростом числа нейронов увеличится число параметров сети, и обучение может занять намного больше времени, особенно если на предыдущем слое также много нейронов.
    * Для удобства просмотра информации о моделе используйте аргумент `name` у слоев.
    * Рекомендуется использовать функциональный API (`keras.models.Model`).
8. При помощи метода `compile()` cконфигурируйте модель, задав оптимизатор, функцию потерь и метрики. Посмотреть информацию о моделе можно при помощи метода `summary()`.
9. Задайте callbacks для вашей модели: `ReduceLROnPlateau`, `EarlyStopping`.
10. Задайте количество эпох и размер батча для обучения. Обучите вашу модель при помощи метода `fit_generator()`. Результат сохраните в переменную history.
    * Для аргумента generator используйте генератор из пункта 6 для тренировочных данных (те, что получены в пункте 5), для validation_data используйте генератор для валидационных данных.
    * В зависимости от вашей моделе для начала можно использовать 20-30 эпох.
    * Используйте батчи размером 16/32/64.
    * Обратите внимание на аргументы steps_per_epoch и validation_steps.
11. Постройте совместные графики метрики и функции потерь для тренировочных и валидационных данных.
12. Предскажите классы для тестовых картинок. Вычислите значение целевой метрики. Сравните качество вашей модели для разных классов.
13. Поэкспериментируйте с архитектурой сети:
    * Попробуйте разное количество нейронов в сети: лучше постепенно увеличивать число нейронов в слоях или уменьшать?
    * Попробуйте другие функции активации
    * Проверьте, увеличивается ли качество при использовании батч-нормализации, как сильно изменяется время обучения с ней/без нее. Лучше использовать ее после или перед функцией активации?
    * Уменьшите/увеличите количество слоев, как это влияет на качество?
    * Сравните различные оптимизаторы. С каким из них сеть сходится лучше/быстрее?
14. Опишите модель, которая показала лучшее качество на тестовых данных: количество слоев, их вид, количество нейронов в них, функция активации и т.д.
15. Отправьте отчет преподавателю на почту.

**Срок сдачи работы: 19 октября 2018.**